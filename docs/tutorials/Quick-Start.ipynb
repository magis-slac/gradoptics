{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import diffoptics as optics\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-layer",
   "metadata": {},
   "source": [
    "# Creating a scene, and producing an image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-jungle",
   "metadata": {},
   "source": [
    "### Creating a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 0.05 # focal length (meters)\n",
    "m = 0.15 # magnification\n",
    "\n",
    "image_pof = -f * (1 + m)\n",
    "object_pof = f * (1 + m) / m\n",
    "\n",
    "# Creating a (thin) lens\n",
    "lens = optics.PerfectLens(f=f, na=1 / 1.4, position=[0., 0., 0.], m=m)\n",
    "\n",
    "## Creating a sensor\n",
    "sensor = optics.Sensor(resolution=(9600, 9600), pixel_size=(3.76e-6, 3.76e-6), \n",
    "                       position=(image_pof, 0, 0), poisson_noise_mean=2, \n",
    "                       quantum_efficiency=0.8)\n",
    "\n",
    "# Creating an Atom Cloud (which is a distribution)\n",
    "atom_cloud = optics.AtomCloud(n=int(1e6), f=2, position=[object_pof, 0., 0.], phi=0.1)\n",
    "\n",
    "# Wrapping the atom cloud to a light source, which will allow to sample photons\n",
    "light_source = optics.LightSourceFromDistribution(atom_cloud)\n",
    "\n",
    "# Creating a scene\n",
    "scene = optics.Scene(light_source)\n",
    "scene.add_object(lens) # Adding the lens to the scene\n",
    "scene.add_object(sensor) # Adding the sensor to the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualizing the scene\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.gca(projection='3d')\n",
    "scene.plot(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-advocacy",
   "metadata": {},
   "source": [
    "### Producing an image from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the cpu for simplicity (everything will be much faster on GPU)\n",
    "device = 'cpu'\n",
    "\n",
    "# Let us start by sampling 10M rays (i.e. 10M photons) from the light source\n",
    "rays = light_source.sample_rays(10_000_000, device=device)\n",
    "\n",
    "# Computing the time at which the rays will intersect the lens\n",
    "t = lens.get_ray_intersection(rays)\n",
    "# Some rays do not intersect the lens, throw them away\n",
    "mask = ~torch.isnan(t)\n",
    "# Computing the rays refracted by the lens\n",
    "refracted_rays, _ = lens.intersect(rays[mask], t[mask])\n",
    "\n",
    "# Repeating the operations on the sensor for the refracted rays\n",
    "t = sensor.get_ray_intersection(refracted_rays)\n",
    "mask = ~torch.isnan(t)\n",
    "sensor.intersect(refracted_rays[mask], t[mask])\n",
    "\n",
    "# Readout the sensor\n",
    "produced_image = sensor.readout(add_poisson_noise=False).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (4800, 4800)\n",
    "w = 40\n",
    "plt.imshow(produced_image[c[0] - w : c[0] + w, c[1] - w : c[1] + w], cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-phrase",
   "metadata": {},
   "source": [
    "### Producing an image with forward ray tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, the built-in function forward_ray_tracing can be used\n",
    "rays = light_source.sample_rays(10_000_000, device=device)\n",
    "optics.forward_ray_tracing(rays, scene, max_iterations=2)\n",
    "\n",
    "# Readout the sensor\n",
    "produced_image = sensor.readout(add_poisson_noise=False).data.cpu().numpy()\n",
    "\n",
    "plt.imshow(produced_image[c[0] - w : c[0] + w, c[1] - w : c[1] + w], cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-pierce",
   "metadata": {},
   "source": [
    "### Producing an image with backward ray tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The built-in fucntion backward_ray_tracing can also be used\n",
    "\n",
    "# Light sources need a bounding shape for being used with backward ray tracing\n",
    "light_source_bounding_shape = optics.BoundingSphere(radii=1e-3, xc=object_pof, yc=0.0, zc=0.0)\n",
    "light_source = optics.LightSourceFromDistribution(atom_cloud, bounding_shape=light_source_bounding_shape)\n",
    "\n",
    "# Computing incident rays from the sensor\n",
    "N = 40\n",
    "px_j, px_i = torch.meshgrid(torch.linspace(N, -N + 1, steps=N * 2), torch.linspace(N, -N + 1, steps=N * 2))\n",
    "px_j = px_j.reshape(-1, 1).type(torch.long)\n",
    "px_i = px_i.reshape(-1, 1).type(torch.long)\n",
    "pos_x = (px_i - 0.5) * sensor.pixel_size[0]\n",
    "pos_y = (px_j - 0.5) * sensor.pixel_size[1]\n",
    "pos_z = torch.zeros(pos_x.shape)\n",
    "origins = torch.cat((pos_x, pos_y, pos_z), dim=1)\n",
    "origins = sensor.c2w.apply_transform_(origins)\n",
    "directions = optics.batch_vector(- origins[:, 0], - origins[:, 1], - origins[:, 2])\n",
    "incident_rays = optics.Rays(origins, directions, device=device)\n",
    "\n",
    "# Producing an image with backward ray tracing\n",
    "integrator = optics.StratifiedSamplingIntegrator(100)\n",
    "image = optics.backward_ray_tracing(incident_rays, scene, light_source, integrator, max_iterations=2)\n",
    "image = image.reshape(2 * N, 2 * N).data.cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
